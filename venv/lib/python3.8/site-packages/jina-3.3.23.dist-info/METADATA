Metadata-Version: 2.1
Name: jina
Version: 3.3.23
Summary: Jina is the cloud-native neural search framework for any kind of data
Home-page: https://github.com/jina-ai/jina/
Author: Jina AI
Author-email: hello@jina.ai
License: Apache 2.0
Download-URL: https://github.com/jina-ai/jina/tags
Project-URL: Documentation, https://docs.jina.ai
Project-URL: Source, https://github.com/jina-ai/jina/
Project-URL: Tracker, https://github.com/jina-ai/jina/issues
Keywords: jina cloud-native neural-search query search index elastic neural-network encoding embedding serving docker container image video audio deep-learning
Platform: UNKNOWN
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Science/Research
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Unix Shell
Classifier: Environment :: Console
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Operating System :: OS Independent
Classifier: Topic :: Database :: Database Engines/Servers
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Internet :: WWW/HTTP :: Indexing/Search
Classifier: Topic :: Scientific/Engineering :: Image Recognition
Classifier: Topic :: Multimedia :: Video
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Scientific/Engineering :: Mathematics
Classifier: Topic :: Software Development
Classifier: Topic :: Software Development :: Libraries
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: fastapi
Requires-Dist: requests
Requires-Dist: prometheus-client
Requires-Dist: aiostream
Requires-Dist: pathspec
Requires-Dist: docker
Requires-Dist: uvicorn[standard]
Requires-Dist: aiofiles
Requires-Dist: filelock
Requires-Dist: numpy
Requires-Dist: pyyaml (>=5.3.1)
Requires-Dist: docarray (>=0.9.10)
Requires-Dist: uvloop
Requires-Dist: cryptography
Requires-Dist: python-multipart
Requires-Dist: grpcio-reflection (<1.44.0,>=1.33.1)
Requires-Dist: rich
Requires-Dist: protobuf (>=3.19.1)
Requires-Dist: pydantic
Requires-Dist: grpcio (<1.44.0,>=1.33.1)
Requires-Dist: packaging (>=20.0)
Requires-Dist: aiohttp
Requires-Dist: websockets
Requires-Dist: lz4 (<3.1.2)
Provides-Extra: pillow
Requires-Dist: Pillow ; extra == 'pillow'
Provides-Extra: aiofiles
Requires-Dist: aiofiles ; extra == 'aiofiles'
Provides-Extra: aiohttp
Requires-Dist: aiohttp ; extra == 'aiohttp'
Provides-Extra: aiostream
Requires-Dist: aiostream ; extra == 'aiostream'
Provides-Extra: all
Requires-Dist: fastapi ; extra == 'all'
Requires-Dist: requests ; extra == 'all'
Requires-Dist: prometheus-client ; extra == 'all'
Requires-Dist: transformers (<=4.2.2) ; extra == 'all'
Requires-Dist: bs4 ; extra == 'all'
Requires-Dist: strawberry-graphql (>=0.96.0) ; extra == 'all'
Requires-Dist: requests-mock ; extra == 'all'
Requires-Dist: pytest-mock ; extra == 'all'
Requires-Dist: portforward (>=0.2.4) ; extra == 'all'
Requires-Dist: coverage (==6.2) ; extra == 'all'
Requires-Dist: pytest-timeout ; extra == 'all'
Requires-Dist: python-multipart ; extra == 'all'
Requires-Dist: pytest-kind (==21.1.3) ; extra == 'all'
Requires-Dist: torchvision (>=0.3.0) ; extra == 'all'
Requires-Dist: rich ; extra == 'all'
Requires-Dist: black (==22.3.0) ; extra == 'all'
Requires-Dist: jsonschema ; extra == 'all'
Requires-Dist: pytest ; extra == 'all'
Requires-Dist: pytest-repeat ; extra == 'all'
Requires-Dist: websockets ; extra == 'all'
Requires-Dist: grpcio (<1.44.0,>=1.33.1) ; extra == 'all'
Requires-Dist: aiostream ; extra == 'all'
Requires-Dist: flaky ; extra == 'all'
Requires-Dist: pathspec ; extra == 'all'
Requires-Dist: docker ; extra == 'all'
Requires-Dist: uvicorn[standard] ; extra == 'all'
Requires-Dist: aiofiles ; extra == 'all'
Requires-Dist: torch (>=1.1.0) ; extra == 'all'
Requires-Dist: pytest-custom-exit-code ; extra == 'all'
Requires-Dist: filelock ; extra == 'all'
Requires-Dist: pytest-reraise ; extra == 'all'
Requires-Dist: numpy ; extra == 'all'
Requires-Dist: pyyaml (>=5.3.1) ; extra == 'all'
Requires-Dist: docarray (>=0.9.10) ; extra == 'all'
Requires-Dist: cryptography ; extra == 'all'
Requires-Dist: uvloop ; extra == 'all'
Requires-Dist: kubernetes (>=18.20.0) ; extra == 'all'
Requires-Dist: pytest-asyncio ; extra == 'all'
Requires-Dist: sgqlc ; extra == 'all'
Requires-Dist: grpcio-reflection (<1.44.0,>=1.33.1) ; extra == 'all'
Requires-Dist: tensorflow (>=2.0) ; extra == 'all'
Requires-Dist: pytest-lazy-fixture ; extra == 'all'
Requires-Dist: mock ; extra == 'all'
Requires-Dist: protobuf (>=3.19.1) ; extra == 'all'
Requires-Dist: pydantic ; extra == 'all'
Requires-Dist: Pillow ; extra == 'all'
Requires-Dist: pytest-cov ; extra == 'all'
Requires-Dist: packaging (>=20.0) ; extra == 'all'
Requires-Dist: aiohttp ; extra == 'all'
Requires-Dist: scipy (>=1.6.1) ; extra == 'all'
Requires-Dist: lz4 (<3.1.2) ; extra == 'all'
Provides-Extra: black
Requires-Dist: black (==22.3.0) ; extra == 'black'
Provides-Extra: bs4
Requires-Dist: bs4 ; extra == 'bs4'
Provides-Extra: cicd
Requires-Dist: sgqlc ; extra == 'cicd'
Requires-Dist: tensorflow (>=2.0) ; extra == 'cicd'
Requires-Dist: jsonschema ; extra == 'cicd'
Requires-Dist: bs4 ; extra == 'cicd'
Requires-Dist: strawberry-graphql (>=0.96.0) ; extra == 'cicd'
Requires-Dist: portforward (>=0.2.4) ; extra == 'cicd'
Provides-Extra: core
Requires-Dist: grpcio-reflection (<1.44.0,>=1.33.1) ; extra == 'core'
Requires-Dist: protobuf (>=3.19.1) ; extra == 'core'
Requires-Dist: numpy ; extra == 'core'
Requires-Dist: packaging (>=20.0) ; extra == 'core'
Requires-Dist: pyyaml (>=5.3.1) ; extra == 'core'
Requires-Dist: docarray (>=0.9.10) ; extra == 'core'
Requires-Dist: grpcio (<1.44.0,>=1.33.1) ; extra == 'core'
Provides-Extra: coverage
Requires-Dist: coverage (==6.2) ; extra == 'coverage'
Provides-Extra: cryptography
Requires-Dist: cryptography ; extra == 'cryptography'
Provides-Extra: demo
Requires-Dist: fastapi ; extra == 'demo'
Requires-Dist: transformers (<=4.2.2) ; extra == 'demo'
Requires-Dist: torchvision (>=0.3.0) ; extra == 'demo'
Requires-Dist: uvicorn[standard] ; extra == 'demo'
Requires-Dist: torch (>=1.1.0) ; extra == 'demo'
Requires-Dist: pydantic ; extra == 'demo'
Provides-Extra: devel
Requires-Dist: fastapi ; extra == 'devel'
Requires-Dist: requests ; extra == 'devel'
Requires-Dist: python-multipart ; extra == 'devel'
Requires-Dist: aiostream ; extra == 'devel'
Requires-Dist: uvloop ; extra == 'devel'
Requires-Dist: pathspec ; extra == 'devel'
Requires-Dist: docker ; extra == 'devel'
Requires-Dist: uvicorn[standard] ; extra == 'devel'
Requires-Dist: rich ; extra == 'devel'
Requires-Dist: aiofiles ; extra == 'devel'
Requires-Dist: pydantic ; extra == 'devel'
Requires-Dist: filelock ; extra == 'devel'
Requires-Dist: aiohttp ; extra == 'devel'
Requires-Dist: websockets ; extra == 'devel'
Requires-Dist: scipy (>=1.6.1) ; extra == 'devel'
Requires-Dist: cryptography ; extra == 'devel'
Requires-Dist: lz4 (<3.1.2) ; extra == 'devel'
Provides-Extra: docarray
Requires-Dist: docarray (>=0.9.10) ; extra == 'docarray'
Provides-Extra: docker
Requires-Dist: docker ; extra == 'docker'
Provides-Extra: fastapi
Requires-Dist: fastapi ; extra == 'fastapi'
Provides-Extra: filelock
Requires-Dist: filelock ; extra == 'filelock'
Provides-Extra: flaky
Requires-Dist: flaky ; extra == 'flaky'
Provides-Extra: graphql
Requires-Dist: sgqlc ; extra == 'graphql'
Requires-Dist: strawberry-graphql (>=0.96.0) ; extra == 'graphql'
Provides-Extra: grpcio
Requires-Dist: grpcio (<1.44.0,>=1.33.1) ; extra == 'grpcio'
Provides-Extra: grpcio-reflection
Requires-Dist: grpcio-reflection (<1.44.0,>=1.33.1) ; extra == 'grpcio-reflection'
Provides-Extra: jsonschema
Requires-Dist: jsonschema ; extra == 'jsonschema'
Provides-Extra: kubernetes
Requires-Dist: kubernetes (>=18.20.0) ; extra == 'kubernetes'
Provides-Extra: lz4
Requires-Dist: lz4 (<3.1.2) ; extra == 'lz4'
Provides-Extra: mock
Requires-Dist: mock ; extra == 'mock'
Provides-Extra: numpy
Requires-Dist: numpy ; extra == 'numpy'
Provides-Extra: packaging
Requires-Dist: packaging (>=20.0) ; extra == 'packaging'
Provides-Extra: pathspec
Requires-Dist: pathspec ; extra == 'pathspec'
Provides-Extra: perf
Requires-Dist: prometheus-client ; extra == 'perf'
Requires-Dist: uvloop ; extra == 'perf'
Requires-Dist: lz4 (<3.1.2) ; extra == 'perf'
Provides-Extra: portforward
Requires-Dist: portforward (>=0.2.4) ; extra == 'portforward'
Provides-Extra: prometheus_client
Requires-Dist: prometheus-client ; extra == 'prometheus_client'
Provides-Extra: protobuf
Requires-Dist: protobuf (>=3.19.1) ; extra == 'protobuf'
Provides-Extra: pydantic
Requires-Dist: pydantic ; extra == 'pydantic'
Provides-Extra: pytest
Requires-Dist: pytest ; extra == 'pytest'
Provides-Extra: pytest-asyncio
Requires-Dist: pytest-asyncio ; extra == 'pytest-asyncio'
Provides-Extra: pytest-cov
Requires-Dist: pytest-cov ; extra == 'pytest-cov'
Provides-Extra: pytest-custom_exit_code
Requires-Dist: pytest-custom-exit-code ; extra == 'pytest-custom_exit_code'
Provides-Extra: pytest-kind
Requires-Dist: pytest-kind (==21.1.3) ; extra == 'pytest-kind'
Provides-Extra: pytest-lazy-fixture
Requires-Dist: pytest-lazy-fixture ; extra == 'pytest-lazy-fixture'
Provides-Extra: pytest-mock
Requires-Dist: pytest-mock ; extra == 'pytest-mock'
Provides-Extra: pytest-repeat
Requires-Dist: pytest-repeat ; extra == 'pytest-repeat'
Provides-Extra: pytest-reraise
Requires-Dist: pytest-reraise ; extra == 'pytest-reraise'
Provides-Extra: pytest-timeout
Requires-Dist: pytest-timeout ; extra == 'pytest-timeout'
Provides-Extra: python-multipart
Requires-Dist: python-multipart ; extra == 'python-multipart'
Provides-Extra: pyyaml
Requires-Dist: pyyaml (>=5.3.1) ; extra == 'pyyaml'
Provides-Extra: requests
Requires-Dist: requests ; extra == 'requests'
Provides-Extra: requests-mock
Requires-Dist: requests-mock ; extra == 'requests-mock'
Provides-Extra: rich
Requires-Dist: rich ; extra == 'rich'
Provides-Extra: scipy
Requires-Dist: scipy (>=1.6.1) ; extra == 'scipy'
Provides-Extra: sgqlc
Requires-Dist: sgqlc ; extra == 'sgqlc'
Provides-Extra: standard
Requires-Dist: fastapi ; extra == 'standard'
Requires-Dist: requests ; extra == 'standard'
Requires-Dist: python-multipart ; extra == 'standard'
Requires-Dist: aiostream ; extra == 'standard'
Requires-Dist: uvloop ; extra == 'standard'
Requires-Dist: pathspec ; extra == 'standard'
Requires-Dist: docker ; extra == 'standard'
Requires-Dist: uvicorn[standard] ; extra == 'standard'
Requires-Dist: rich ; extra == 'standard'
Requires-Dist: aiofiles ; extra == 'standard'
Requires-Dist: pydantic ; extra == 'standard'
Requires-Dist: filelock ; extra == 'standard'
Requires-Dist: aiohttp ; extra == 'standard'
Requires-Dist: websockets ; extra == 'standard'
Requires-Dist: cryptography ; extra == 'standard'
Requires-Dist: lz4 (<3.1.2) ; extra == 'standard'
Provides-Extra: strawberry-graphql
Requires-Dist: strawberry-graphql (>=0.96.0) ; extra == 'strawberry-graphql'
Provides-Extra: tensorflow
Requires-Dist: tensorflow (>=2.0) ; extra == 'tensorflow'
Provides-Extra: test
Requires-Dist: kubernetes (>=18.20.0) ; extra == 'test'
Requires-Dist: flaky ; extra == 'test'
Requires-Dist: pytest-asyncio ; extra == 'test'
Requires-Dist: pytest-kind (==21.1.3) ; extra == 'test'
Requires-Dist: pytest-lazy-fixture ; extra == 'test'
Requires-Dist: coverage (==6.2) ; extra == 'test'
Requires-Dist: mock ; extra == 'test'
Requires-Dist: black (==22.3.0) ; extra == 'test'
Requires-Dist: Pillow ; extra == 'test'
Requires-Dist: pytest-custom-exit-code ; extra == 'test'
Requires-Dist: pytest-reraise ; extra == 'test'
Requires-Dist: pytest-cov ; extra == 'test'
Requires-Dist: pytest ; extra == 'test'
Requires-Dist: pytest-repeat ; extra == 'test'
Requires-Dist: requests-mock ; extra == 'test'
Requires-Dist: pytest-mock ; extra == 'test'
Requires-Dist: pytest-timeout ; extra == 'test'
Provides-Extra: torch
Requires-Dist: torch (>=1.1.0) ; extra == 'torch'
Provides-Extra: torchvision
Requires-Dist: torchvision (>=0.3.0) ; extra == 'torchvision'
Provides-Extra: transformers
Requires-Dist: transformers (<=4.2.2) ; extra == 'transformers'
Provides-Extra: uvicorn_standard_
Requires-Dist: uvicorn[standard] ; extra == 'uvicorn_standard_'
Provides-Extra: uvloop
Requires-Dist: uvloop ; extra == 'uvloop'
Provides-Extra: websockets
Requires-Dist: websockets ; extra == 'websockets'

<p align="center">
<br><br><br>
<a href="https://docs.jina.ai"><img src="https://github.com/jina-ai/jina/blob/master/docs/_static/logo-light.svg?raw=true" alt="Jina logo: Jina is a cloud-native neural search framework" width="150px"></a>
<br><br><br>
</p>

<p align="center">
<b>Cloud-Native Neural Search<sup><a href="https://docs.jina.ai/get-started/neural-search/">?</a></sup> Framework for <i>Any</i> Kind of Data</b>
</p>


<p align=center>
<a href="https://github.com/jina-ai/jina/actions/workflows/cd.yml"><img alt="Github CD status" src="https://github.com/jina-ai/jina/actions/workflows/cd.yml/badge.svg"></a>
<a href="https://pypi.org/project/jina/"><img alt="PyPI" src="https://img.shields.io/pypi/v/jina?label=PyPI&logo=pypi&logoColor=white&style=flat-square"></a>
<a href="https://codecov.io/gh/jina-ai/jina"><img alt="Codecov branch" src="https://img.shields.io/codecov/c/github/jina-ai/jina/master?logo=Codecov&logoColor=white&style=flat-square"></a>
<a href="https://slack.jina.ai"><img src="https://img.shields.io/badge/Slack-2.8k-blueviolet?logo=slack&amp;logoColor=white&style=flat-square"></a>
<a href="https://hub.docker.com/r/jinaai/jina/tags"><img alt="Docker Pulls" src="https://img.shields.io/docker/pulls/jinaai/jina?logo=Docker&style=social"></a>
</p>

<!-- start jina-description -->

Jina is a neural search framework that empowers anyone to build SOTA and scalable neural search applications in minutes.

‚è±Ô∏è **Save time** - *The* design pattern of neural search systems. Quickly build solutions for indexing, querying, understanding multi-/cross-modal data such as video, image, text, audio, source code, PDF.

üå©Ô∏è **Local & cloud friendly** - Distributed architecture, scalable & cloud-native from day one. Same developer experience on local, [Docker Compose](https://docs.jina.ai/how-to/docker-compose/), [Kubernetes](https://docs.jina.ai/how-to/kubernetes/).

üöÄ **Serve, scale & share** - Serve a local project with HTTP, WebSockets or gRPC endpoints in just minutes. Scale your neural search applications to meet your availability and throughput requirements. Share and reuse building blocks from [Hub](https://hub.jina.ai).

üç± **Own your stack** - Keep end-to-end stack ownership of your solution. Avoid integration pitfalls you get with fragmented, multi-vendor, generic legacy tools. Enjoy the integration with the neural search ecosystem including [DocArray](https://docarray.jina.ai), [Hub](https://hub.jina.ai) and [Finetuner](https://finetuner.jina.ai).

<!-- end jina-description -->

## Install 

```bash
pip install jina
```

For Jina 2.x users, please uninstall it via `pip uninstall jina` before installing Jina 3. Please also read [the 2 to 3 migration guide](https://docs.jina.ai/get-started/migrate/).

More install options including Conda, Docker, and Windows [can be found here](https://docs.jina.ai/get-started/install/).

## [Documentation](https://docs.jina.ai)

## Get Started



We promise you can build a **scalable** ResNet-powered image search **service** in 20 minutes or less, **from scratch to Kubernetes**. If not, you can forget about Jina.

### Basic Concepts

Document, Executor and Flow are three fundamental concepts in Jina.

- [**Document**](https://docarray.jina.ai/) is a data structure contains multi-modal data.
- [**Executor**](https://docs.jina.ai/fundamentals/executor/) is a self-contained component and performs a group of tasks on Documents.
- [**Flow**](https://docs.jina.ai/fundamentals/flow/) ties Executors together into a processing pipeline, provides scalability and facilitates deployments in the cloud.

Leveraging these three concepts, let's build a simple image search service, as a "productization" of [DocArray README](https://github.com/jina-ai/docarray#a-complete-workflow-of-visual-search). 


<p align="center">
<a href="https://docs.jina.ai"><img src="https://github.com/jina-ai/jina/blob/master/.github/images/readme-banner1.svg?raw=true" alt="Get started with Jina to build production-ready neural search solution via ResNet in less than 20 minutes" width="100%"></a>
</p>

### Build a service from scratch

<sup>
Preliminaries: <a href="https://pytorch.org/get-started/locally/">install PyTorch & Torchvision</a>
</sup>

1. Import what we need.
    ```python
    from docarray import Document, DocumentArray
    from jina import Executor, Flow, requests
    ```
2. Copy-paste the preprocessing step and wrap it via `Executor`:
    ```python
    class PreprocImg(Executor):
        @requests
        async def foo(self, docs: DocumentArray, **kwargs):
            for d in docs:
                (
                    d.load_uri_to_image_tensor(200, 200)  # load
                    .set_image_tensor_normalization()  # normalize color
                    .set_image_tensor_channel_axis(
                        -1, 0
                    )  # switch color axis for the PyTorch model later
                )
    ```
3. Copy-paste the embedding step and wrap it via `Executor`:
    
    ```python   
    class EmbedImg(Executor):
        def __init__(self, **kwargs):
            super().__init__(**kwargs)
            import torchvision
            self.model = torchvision.models.resnet50(pretrained=True)        
   
        @requests
        async def foo(self, docs: DocumentArray, **kwargs):
            docs.embed(self.model)
    ```
4. Wrap the matching step into an `Executor`:
    ```python
    class MatchImg(Executor):
        _da = DocumentArray()

        @requests(on='/index')
        async def index(self, docs: DocumentArray, **kwargs):
            self._da.extend(docs)
            docs.clear()  # clear content to save bandwidth

        @requests(on='/search')
        async def foo(self, docs: DocumentArray, **kwargs):
            docs.match(self._da, limit=9)
            del docs[...][:, ('embedding', 'tensor')]  # save bandwidth as it is not needed
    ```
5. Connect all `Executor`s in a `Flow`, scale embedding to 3:
    ```python
    f = (
        Flow(port=12345)
        .add(uses=PreprocImg)
        .add(uses=EmbedImg, replicas=3)
        .add(uses=MatchImg)
    )
    ```
    Plot it via `f.plot('flow.svg')` and you get:
    
    <p align="center">
    <img src="https://github.com/jina-ai/jina/blob/master/.github/images/readme-flow-plot.svg?raw=true" title="Jina Flow.plot visualization" width="65%">
    </p>
    
6. Download the image dataset.


<table>
<tr>
<th> Pull from Cloud </th> 
<th> Manually download, unzip and load </th>
</tr>
<tr>
<td> 

```python
index_data = DocumentArray.pull('demo-leftda', show_progress=True)
```
     
</td>
<td>

1. Download `left.zip` from [Google Drive](https://sites.google.com/view/totally-looks-like-dataset)
2. Unzip all images to `./left/`
3. Load into DocumentArray
    ```python
    index_data = DocumentArray.from_files('left/*.jpg')
    ```

</td>
</tr>
</table>

    
7. Index image data:
    ```python
    with f:
        f.post(
            '/index',
            index_data,
            show_progress=True,
            request_size=8,
        )
        f.block()
    ```

The full indexing on 6,000 images should take ~8 minutes on a MacBook Air 2020.

Now you can use a Python client to access the service:

```python
from jina import Client

c = Client(port=12345)  # connect to localhost:12345
print(c.post('/search', index_data[0])['@m'])  # '@m' is the matches-selector
```

To switch from gRPC interface to REST API, you can simply set `protocol = 'http'`:

```python
with f:
    ...
    f.protocol = 'http'
    f.block()
```

Now you can query it via `curl`:

<p align="center">
<a href="https://docs.jina.ai"><img src="https://github.com/jina-ai/jina/blob/master/.github/images/readme-curl.png?raw=true" alt="Use curl to query image search service built by Jina & ResNet50" width="80%"></a>
</p>

Or go to `http://0.0.0.0:12345/docs` and test requests via a Swagger UI:

<p align="center">
<a href="https://docs.jina.ai"><img src="https://github.com/jina-ai/jina/blob/master/.github/images/readme-swagger-ui.gif?raw=true" alt="Visualize visual similar images in Jina using ResNet50" width="60%"></a>
</p>




<p align="center">
<a href="https://docs.jina.ai"><img src="https://github.com/jina-ai/jina/blob/master/.github/images/readme-banner2.svg?raw=true" alt="Get started with Jina to build production-ready neural search solution via ResNet in less than 20 minutes" width="100%"></a>
</p>

### Play with Containerized Executors

You can containerize the Executors and use them in a sandbox thanks to [Hub](https://hub.jina.ai).

1. Move each `Executor` class to a separate folder with one Python file in each:
   - `PreprocImg` -> üìÅ `preproc_img/exec.py`
   - `EmbedImg` -> üìÅ `embed_img/exec.py`
   - `MatchImg` -> üìÅ `match_img/exec.py`
2. Create a `requirements.txt` in `embed_img` as it requires `torchvision`.

    ```text
    .
    ‚îú‚îÄ‚îÄ embed_img
    ‚îÇ     ‚îú‚îÄ‚îÄ exec.py  # copy-paste codes of ImageEmbeddingExecutor
    ‚îÇ     ‚îî‚îÄ‚îÄ requirements.txt  # add the requirement `torchvision`
    ‚îî‚îÄ‚îÄ match_img
          ‚îî‚îÄ‚îÄ exec.py  # copy-paste codes of IndexExecutor
    ‚îî‚îÄ‚îÄ preproc_img
          ‚îî‚îÄ‚îÄ exec.py  # copy-paste codes of IndexExecutor
    ```
3. Push all Executors to the [Hub](https://hub.jina.ai):
    ```bash
    jina hub push preproc_img
    jina hub push embed_img
    jina hub push match_img
    ```
   You will get three Hub Executors that can be used via Sandbox, Docker container or source code. 

<p align="center">
<a href="https://docs.jina.ai"><img src="https://github.com/jina-ai/jina/blob/master/.github/images/readme-hub-push.png?raw=true" alt="Jina hub push gives you the sandbox" width="70%"></a>
</p>

4. In particular, Sandbox hosts your Executor on Jina Cloud and allows you to use it from your local machine:
    ```python
    from docarray import DocumentArray
    from jina import Flow

    index_data = DocumentArray.pull(
        'demo-leftda', show_progress=True
    )  # Download the dataset as shown in the tutorial above

    f = Flow().add(uses='jinahub+sandbox://2k7gsejl')

    with f:
        print(f.post('/', index_data[:10]))
    ```

<p align="center">
<a href="https://docs.jina.ai"><img alt="Shell outputs running docker-compose" src="https://github.com/jina-ai/jina/blob/master/.github/images/readme-sandbox-play.png?raw=ture" title="outputs of docker-compose" width="90%"></a>
</p>


<p align="center">
<a href="https://docs.jina.ai"><img src="https://github.com/jina-ai/jina/blob/master/.github/images/readme-banner3.svg?raw=true" alt="Containerize, share and play in one-place like a pro" width="100%"></a>
</p>


### Deploy the service via Docker Compose

1. Now that all Executors are in containers, we can easily use Docker Compose to orchestrate the Flow:

    ```python
    f = (
        Flow(port=12345)
        .add(uses='jinahub+docker://1ylut0gf')
        .add(uses='jinahub+docker://258lzh3c')
    )
    f.to_docker_compose_yaml()  # By default, stored at `docker-compose.yml`
    ```

2. Now in the console run:

    ```shell
    docker-compose up
    ```

<p align="center">
<a href="https://docs.jina.ai"><img alt="Shell outputs running docker-compose" src="https://github.com/jina-ai/jina/blob/master/.github/images/readme-docker-compose.png?raw=ture" title="She;; outputs of docker-compose"  width="85%"></a>
</p>

### Deploy the service via Kubernetes

1. Create a Kubernetes cluster and get credentials (example in GCP, [more K8s providers here](https://docs.jina.ai/advanced/experimental/kubernetes/#preliminaries)):
    ```bash
    gcloud container clusters create test --machine-type e2-highmem-2  --num-nodes 1 --zone europe-west3-a
    gcloud container clusters get-credentials test --zone europe-west3-a --project jina-showcase
    ```

2. Create a namespace `flow-k8s-namespace` for demonstration purpose:
    ```bash
    kubectl create namespace flow-k8s-namespace
    ```

3. Generate the kubernetes configuration files using one line of code:
    ```python
    f.to_k8s_yaml('./k8s_config', k8s_namespace='flow-k8s-namespace')
    ```
    
4. Your `k8s_config` folder will look like the following:
    ```shell
    k8s_config
    ‚îú‚îÄ‚îÄ executor0
    ‚îÇ     ‚îú‚îÄ‚îÄ executor0-head.yml
    ‚îÇ     ‚îî‚îÄ‚îÄ executor0.yml
    ‚îú‚îÄ‚îÄ executor1
    ‚îÇ     ‚îú‚îÄ‚îÄ executor1-head.yml
    ‚îÇ     ‚îî‚îÄ‚îÄ executor1.yml
    ‚îî‚îÄ‚îÄ gateway
          ‚îî‚îÄ‚îÄ gateway.yml
    ```

5. Use `kubectl` to deploy your neural search application: 

    ```shell
    kubectl apply -R -f ./k8s_config
    ```

<p align="center">
<a href="https://docs.jina.ai"><img alt="Shell outputs running k8s" src="https://github.com/jina-ai/jina/blob/master/.github/images/readme-k8s.png?raw=ture" title="kubernetes outputs" width="70%"></a>
</p>

6. Run port forwarding so that you can send requests to your Kubernetes application from local CLI : 

    ```shell
    kubectl port-forward svc/gateway -n flow-k8s-namespace 12345:12345
    ```

Now we have the service up running in Kubernetes!


## Run Quick Demo

- [üëó Fashion image search](https://docs.jina.ai/get-started/hello-world/fashion/): `jina hello fashion`
- [ü§ñ QA chatbot](https://docs.jina.ai/get-started/hello-world/covid-19-chatbot/): `pip install "jina[demo]" && jina hello chatbot`
- [üì∞ Multimodal search](https://docs.jina.ai/get-started/hello-world/multimodal/): `pip install "jina[demo]" && jina hello multimodal`
- üç¥ Fork the source of a demo to your folder: `jina hello fork fashion ../my-proj/`
- Create a new Jina project: `jina new hello-jina`

<!-- start support-pitch -->

## Support

- Check out the [Learning Bootcamp](https://learn.jina.ai) to get started with Jina.
- Join our [Slack community](https://slack.jina.ai) to chat to our engineers about your use cases, questions, and
  support queries.
- Join our [Engineering All Hands](https://youtube.com/playlist?list=PL3UBBWOUVhFYRUa_gpYYKBqEAkO4sxmne) meet-up to
  discuss your use case and learn Jina's new features.
    - **When?** The second Tuesday of every month
    - **Where?**
      Zoom ([see our public calendar](https://calendar.google.com/calendar/embed?src=c_1t5ogfp2d45v8fit981j08mcm4%40group.calendar.google.com&ctz=Europe%2FBerlin)/[.ical](https://calendar.google.com/calendar/ical/c_1t5ogfp2d45v8fit981j08mcm4%40group.calendar.google.com/public/basic.ics)/[Meetup
      group](https://www.meetup.com/jina-community-meetup/))
      and [live stream on YouTube](https://youtube.com/c/jina-ai)
- Subscribe to the latest video tutorials on our [YouTube channel](https://youtube.com/c/jina-ai)

## Join Us

Jina is backed by [Jina AI](https://jina.ai) and licensed under [Apache-2.0](./LICENSE).
[We are actively hiring](https://jobs.jina.ai) AI engineers, solution engineers to build the next neural search
ecosystem in open source.

<!-- end support-pitch -->

## Contribute

We welcome all kinds of contributions from the open-source community, individuals and partners. We owe our success to
your active involvement.

- [Release cycles and development stages](RELEASE.md)
- [Contributing guidelines](CONTRIBUTING.md)
- [Code of conduct](https://github.com/jina-ai/jina/blob/master/.github/CODE_OF_CONDUCT.md)


